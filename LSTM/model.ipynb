{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/bittlingmayer/amazonreviews\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# from torchtext.data import get_tokenizer\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        label, text = line.split(' ', 1)\n",
    "        label_number = int(label.replace('__label__', ''))\n",
    "        data.append({'label': label_number, 'text': text.strip()})\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create dataframes for the training and testing data\n",
    "train_df = create_dataframe_from_file('data/train.ft.txt')\n",
    "test_df = create_dataframe_from_file('data/test.ft.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  Stuning even for the non-gamer: This sound tra...\n",
       "1      2  The best soundtrack ever to anything.: I'm rea...\n",
       "2      2  Amazing!: This soundtrack is my favorite music...\n",
       "3      2  Excellent Soundtrack: I truly like this soundt...\n",
       "4      2  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(label\n",
       " 1    1800000\n",
       " 0    1800000\n",
       " Name: count, dtype: int64,\n",
       " label\n",
       " 1    200000\n",
       " 0    200000\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'] = train_df['label'] - 1\n",
    "test_df['label'] = test_df['label'] - 1\n",
    "train_df['label'].value_counts(), test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_df = train_df.sample(n=100000, random_state=42)\n",
    "sampled_test_df = test_df.sample(n=20000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preprocess the text data\n",
    "# Define the tokenizer\n",
    "def tokenizer(text):\n",
    "    return [token.text for token in nlp(text)]\n",
    "\n",
    "# Tokenize the input text\n",
    "def tokenize_iterator(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def build_vocab(data_iter, min_freq=10, specials=['<unk>', '<pad>']):\n",
    "    counter = Counter()\n",
    "    for text in data_iter:\n",
    "        tokens = tokenizer(text)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    word_to_index = {word: i + len(specials) for i, (word, _) in enumerate(counter.most_common()) if word not in specials and counter[word] >= min_freq}\n",
    "    for i, special in enumerate(specials):\n",
    "        word_to_index[special] = i\n",
    "    return word_to_index\n",
    "\n",
    "vocab = build_vocab(sampled_train_df['text'])\n",
    "\n",
    "# Define the text_pipeline function\n",
    "def text_pipeline(text):\n",
    "    return [vocab.get(token, vocab['<unk>']) for token in tokenizer(text)]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(_label)\n",
    "        text_list.append(torch.tensor(text_pipeline(_text)))  # Convert list to tensor\n",
    "    return torch.tensor(label_list, dtype=torch.int64), nn.utils.rnn.pad_sequence(text_list, padding_value=vocab['<pad>'], batch_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use train_df for training data and test_df for validation data\n",
    "train_data, val_data = sampled_train_df, sampled_test_df\n",
    "\n",
    "# 3. Create a PyTorch Dataset and DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]\n",
    "\n",
    "train_dataset = TextDataset(train_data)\n",
    "val_dataset = TextDataset(val_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 4. Define an LSTM model architecture\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 128\n",
    "hidden_dim = 256\n",
    "num_classes = 3\n",
    "\n",
    "model = LSTMModel(vocab_size, embed_dim, hidden_dim, num_classes).to(device)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in train_data: [0 1]\n",
      "Unique labels in test_data: [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in train_data:\", np.unique(train_df[\"label\"]))\n",
    "print(\"Unique labels in test_data:\", np.unique(test_df[\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader for the test dataset\n",
    "test_data = TextDataset(test_df)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.0109, Train Acc: 0.5006, Test Loss: 0.0108, Test Acc: 0.4988\n",
      "Epoch 2/10, Train Loss: 0.0075, Train Acc: 0.7516, Test Loss: 0.0053, Test Acc: 0.8568\n",
      "Epoch 3/10, Train Loss: 0.0044, Train Acc: 0.8880, Test Loss: 0.0046, Test Acc: 0.8841\n",
      "Epoch 4/10, Train Loss: 0.0036, Train Acc: 0.9116, Test Loss: 0.0043, Test Acc: 0.8944\n",
      "Epoch 5/10, Train Loss: 0.0031, Train Acc: 0.9244, Test Loss: 0.0042, Test Acc: 0.8990\n",
      "Epoch 6/10, Train Loss: 0.0028, Train Acc: 0.9336, Test Loss: 0.0042, Test Acc: 0.9010\n",
      "Epoch 7/10, Train Loss: 0.0025, Train Acc: 0.9414, Test Loss: 0.0041, Test Acc: 0.9003\n",
      "Epoch 8/10, Train Loss: 0.0023, Train Acc: 0.9472, Test Loss: 0.0041, Test Acc: 0.9036\n",
      "Epoch 9/10, Train Loss: 0.0022, Train Acc: 0.9511, Test Loss: 0.0044, Test Acc: 0.8984\n",
      "Epoch 10/10, Train Loss: 0.0021, Train Acc: 0.9533, Test Loss: 0.0044, Test Acc: 0.9012\n"
     ]
    }
   ],
   "source": [
    "# 5. Train the model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    # Training\n",
    "    for labels, texts in train_dataloader:\n",
    "        labels, texts = labels.to(device), texts.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_data)\n",
    "    train_acc /= len(train_data)\n",
    "    \n",
    "    # Switch the model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    \n",
    "    # Calculate the test loss and accuracy during evaluation\n",
    "    with torch.no_grad():\n",
    "        for labels, texts in val_dataloader:\n",
    "            labels, texts = labels.to(device), texts.to(device)\n",
    "            \n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (outputs.argmax(1) == labels).sum().item()\n",
    "    \n",
    "    test_loss /= len(val_data)\n",
    "    test_acc /= len(val_data)\n",
    "\n",
    "    # Print or store the test results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    # Switch the model back to training mode\n",
    "    model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
