{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./cnn_dailymail/train.csv\")\n",
    "val_df = pd.read_csv(\"./cnn_dailymail/validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3</td>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "      <td>Sally Forrest, an actress-dancer who graced th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21c0bd69b7e7df285c3d1b1cf56d4da925980a68</td>\n",
       "      <td>A middle-school teacher in China has inked hun...</td>\n",
       "      <td>Works include pictures of Presidential Palace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56f340189cd128194b2e7cb8c26bb900e3a848b4</td>\n",
       "      <td>A man convicted of killing the father and sist...</td>\n",
       "      <td>Iftekhar Murtaza, 29, was convicted a year ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00a665151b89a53e5a08a389df8334f4106494c2</td>\n",
       "      <td>Avid rugby fan Prince Harry could barely watch...</td>\n",
       "      <td>Prince Harry in attendance for England's crunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9f6fbd3c497c4d28879bebebea220884f03eb41a</td>\n",
       "      <td>A Triple M Radio producer has been inundated w...</td>\n",
       "      <td>Nick Slater's colleagues uploaded a picture to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id   \n",
       "0  61df4979ac5fcc2b71be46ed6fe5a46ce7f071c3  \\\n",
       "1  21c0bd69b7e7df285c3d1b1cf56d4da925980a68   \n",
       "2  56f340189cd128194b2e7cb8c26bb900e3a848b4   \n",
       "3  00a665151b89a53e5a08a389df8334f4106494c2   \n",
       "4  9f6fbd3c497c4d28879bebebea220884f03eb41a   \n",
       "\n",
       "                                             article   \n",
       "0  Sally Forrest, an actress-dancer who graced th...  \\\n",
       "1  A middle-school teacher in China has inked hun...   \n",
       "2  A man convicted of killing the father and sist...   \n",
       "3  Avid rugby fan Prince Harry could barely watch...   \n",
       "4  A Triple M Radio producer has been inundated w...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Sally Forrest, an actress-dancer who graced th...  \n",
       "1  Works include pictures of Presidential Palace ...  \n",
       "2  Iftekhar Murtaza, 29, was convicted a year ago...  \n",
       "3  Prince Harry in attendance for England's crunc...  \n",
       "4  Nick Slater's colleagues uploaded a picture to...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first 5 rows\n",
    "val_df_sample = val_df.head(5)\n",
    "\n",
    "# Save to a .pkl file\n",
    "val_df_sample.to_pickle(\"./val_df_sample.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude article length outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new column in the dataframe that contains the lengths of the articles\n",
    "train_df['article_length'] = train_df['article'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot a histogram of the article lengths\n",
    "train_df['article_length'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          37\n",
       "1          38\n",
       "2          69\n",
       "3          53\n",
       "4          67\n",
       "         ... \n",
       "287108     42\n",
       "287109    108\n",
       "287110     56\n",
       "287111     55\n",
       "287112     59\n",
       "Name: highlights_length, Length: 287113, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new column in the dataframe that contains the lengths of the articles\n",
    "train_df['highlights_length'] = train_df['highlights'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot a histogram of the article lengths\n",
    "train_df['highlights_length'].hist(bins=2)\n",
    "train_df['highlights_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    287113.000000\n",
      "mean        691.869494\n",
      "std         336.500035\n",
      "min           8.000000\n",
      "25%         443.000000\n",
      "50%         632.000000\n",
      "75%         877.000000\n",
      "max        2347.000000\n",
      "Name: article_length, dtype: float64\n",
      "count    287113.000000\n",
      "mean         51.574101\n",
      "std          21.256336\n",
      "min           4.000000\n",
      "25%          38.000000\n",
      "50%          48.000000\n",
      "75%          60.000000\n",
      "max        1296.000000\n",
      "Name: highlights_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['article_length'].describe())\n",
    "print(train_df['highlights_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median and interquartile range of article length\n",
    "median_length = train_df['article_length'].median()\n",
    "Q1 = train_df['article_length'].quantile(0.25)\n",
    "Q3 = train_df['article_length'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds for article length\n",
    "lower_bound = max(0, Q1 - 1.5*IQR) # We take max with 0 to avoid negative lengths\n",
    "upper_bound = Q3 + 1.5*IQR\n",
    "\n",
    "# Filter DataFrame to only include articles within bounds\n",
    "filtered_df = train_df[(train_df['article_length'] >= lower_bound) & \n",
    "                       (train_df['article_length'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7183"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of outliers excluded\n",
    "len(train_df) - len(filtered_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode data\n",
    "\n",
    "def data_process(data, tokenizer):\n",
    "    raw_src_iter = iter(data['article'])\n",
    "    raw_tgt_iter = iter(data['highlights'])\n",
    "    src_data = []\n",
    "    tgt_data = []\n",
    "    for (raw_src, raw_tgt) in zip(raw_src_iter, raw_tgt_iter):\n",
    "        src_tensor_ = torch.tensor(tokenizer.encode(raw_src, truncation=True, max_length=800), dtype=torch.long)\n",
    "        tgt_tensor_ = torch.tensor(tokenizer.encode(raw_tgt, truncation=True, max_length=80), dtype=torch.long)\n",
    "        src_data.append(src_tensor_)\n",
    "        tgt_data.append(tgt_tensor_)\n",
    "\n",
    "    # pad the sequences\n",
    "    src_data = pad_sequence(src_data, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    tgt_data = pad_sequence(tgt_data, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return src_data, tgt_data\n",
    "\n",
    "\n",
    "train_inputs, train_targets = data_process(filtered_df, tokenizer) # list of (source tensor - (512), target tensor (512))\n",
    "val_inputs, val_targets = data_process(val_df, tokenizer)\n",
    "\n",
    "# Saved trained tokenizer training data (around 45 minutes to train)\n",
    "import pickle\n",
    "\n",
    "# Save training inputs\n",
    "with open('train_inputs2.pkl', 'wb') as file:\n",
    "    pickle.dump(train_inputs, file)\n",
    "# Save training targets\n",
    "with open('train_targets2.pkl', 'wb') as file:\n",
    "    pickle.dump(train_targets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open('train_inputs.pkl', 'rb') as file:\n",
    "    train_inputs = pickle.load(file)\n",
    "with open('train_targets.pkl', 'rb') as file:\n",
    "    train_targets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape: torch.Size([10, 512])\n",
      "Target shape: torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "test_batch = train_inputs[:10]\n",
    "target_batch = train_targets[:10]\n",
    "print(f'Source shape: {test_batch.shape}') # tensor representation of article's tokens\n",
    "print(f'Target shape: {target_batch.shape}') # tensor representation of article's targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512, 256])\n",
      "torch.Size([10, 512, 1024])\n",
      "torch.Size([2, 10, 512])\n",
      "torch.Size([10, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 512, 1024]), torch.Size([10, 512]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = test_batch\n",
    "\n",
    "INPUT_DIM = tokenizer.vocab_size\n",
    "EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "DROPOUT = 0.5\n",
    "\n",
    "print(src.shape) # shape of initial source tensor\n",
    "embds = nn.Embedding(INPUT_DIM, EMB_DIM)(src)\n",
    "print(embds.shape) # shape of embeddings for source tensor (one embedding vector of dimension EMB_DIM for each token in each sequence)\n",
    "outs, hid = nn.GRU(EMB_DIM, ENC_HID_DIM, bidirectional=True, batch_first=True)(embds)\n",
    "# shape of the output of the last layer of the GRU (the final output), which is (src length, ENC_HID_DIM times 2, since the GRU is bidirectional) for each sequence\n",
    "print(outs.shape)\n",
    "print(hid.shape) # shape of the final hidden state of the GRU, which is (number of directions, n_seq, ENC_HID_DIM)\n",
    "fc = nn.Linear(ENC_HID_DIM*2, DEC_HID_DIM) # linear layer with input and output sizes defined\n",
    "fc_inp = torch.cat((hid[-2, :, :], hid[-1, :, :]), dim=1) # concatenate forward and backward hidden states for each sequence\n",
    "fc_act = torch.tanh(fc(fc_inp)) # apply fully connected layer to hidden states, then apply a non-linearity (tanh)\n",
    "print(fc_act.shape)\n",
    "\n",
    "# outputs of the decoder - all GRU outputs (both directions concatenated for each token in each sequence), final hidden states of each sequence\n",
    "outs.shape, fc_act.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.shape[1]\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden state: torch.Size([10, 512])\n",
      "Encoder outputs: torch.Size([10, 512, 1024])\n",
      "----\n",
      "Hidden state: torch.Size([10, 512, 512])\n",
      "Encoder outputs: torch.Size([10, 512, 1024])\n",
      "----\n",
      "Input to energy (concatenated hidden and encoder outputs states): torch.Size([10, 512, 1536])\n",
      "Energy result: torch.Size([10, 512, 512])\n",
      "----\n",
      "Encoder output - Decoder hidden state energy values: torch.Size([10, 512])\n",
      "Softmax results (attention outputs): torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder_outs = outs, fc_act # output of the encoder\n",
    "outputs = encoder_outs[0]\n",
    "hidden_og = encoder_outs[1]\n",
    "seq_len = outputs.shape[1] # length of each sequence in the batch (512)\n",
    "batch_size = outputs.shape[0] # number of sequences in the batch (10)\n",
    "print(f'Hidden state: {hidden_og.shape}')\n",
    "print(f'Encoder outputs: {outputs.shape}')\n",
    "print('----')\n",
    "\n",
    "hidden = hidden_og.unsqueeze(1).repeat(1,seq_len,1) # repeat the hidden states for each sequence seq_len times\n",
    "print(f'Hidden state: {hidden.shape}')\n",
    "print(f'Encoder outputs: {outputs.shape}')\n",
    "print('----')\n",
    "\n",
    "attn_inp = torch.cat((hidden, outputs), dim=2)\n",
    "attn = nn.Linear((ENC_HID_DIM * 2) + DEC_HID_DIM, DEC_HID_DIM) # linear layer that takes computes the energy between the hidden state and each encoder output\n",
    "energy = torch.tanh(attn(attn_inp))\n",
    "print(f'Input to energy (concatenated hidden and encoder outputs states): {attn_inp.shape}') \n",
    "print(f'Energy result: {energy.shape}') # 512-dimensional vector for each token in each sequence (info on how useful the encoder output is to the hidden state)\n",
    "print('----')\n",
    "\n",
    "v = nn.Linear(DEC_HID_DIM, 1, bias=False) # linear layer that transforms energy vector into a value between 0 and 1 for each token in each sequence\n",
    "energy_vals = v(energy).squeeze(2) # compute how important each encoder output is to the decoder hidden state (squeeze to reduce to 2 dimensions)\n",
    "print(f'Encoder output - Decoder hidden state energy values: {energy_vals.shape}')\n",
    "attn_outs = F.softmax(energy_vals, dim=1) # pass through a softmax\n",
    "print(f'Softmax results (attention outputs): {attn_outs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(2)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.transpose(1,2)\n",
    "        # print(a.shape, encoder_outputs.shape)\n",
    "        weighted = torch.bmm(encoder_outputs, a) # context vectors\n",
    "        weighted = weighted.squeeze(2).unsqueeze(0)\n",
    "\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "\n",
    "        # Squeeze the output tensors from the GRU\n",
    "        output = output.squeeze(0)\n",
    "        hidden = hidden.squeeze(0)\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "\n",
    "        return prediction, hidden, a.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 512, 1024])\n",
      "torch.Size([10, 512, 512])\n",
      "torch.Size([10])\n",
      "----\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10, 256])\n",
      "----\n",
      "torch.Size([10, 1024, 512])\n",
      "torch.Size([10, 512, 1])\n",
      "torch.Size([10, 1024, 1])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(src.shape)\n",
    "attn_outs = attn_outs\n",
    "print(attn_outs.shape)\n",
    "outputs = encoder_outs[0]\n",
    "print(outputs.shape)\n",
    "# hidden = encoder_outs[1]\n",
    "print(hidden.shape)\n",
    "sos_token_id = tokenizer.eos_token_id  # Get the SOS token ID\n",
    "sos_token_tensor = torch.tensor([sos_token_id] * 10)  # Convert it into a tensor of 10 sos token ids (sos and eos are equivalent in GPT-2 tokenizer)\n",
    "print(sos_token_tensor.shape) \n",
    "print('----')\n",
    "\n",
    "embd_layer = nn.Embedding(INPUT_DIM, EMB_DIM)\n",
    "embd_inp = sos_token_tensor.unsqueeze(0) # create an extra dim so this can be an input to the embedding layer\n",
    "print(embd_inp.shape)\n",
    "sos_embds = embd_layer(embd_inp) # returns an embedding vector for each token (at this point, 1 token per sequence in the batch)\n",
    "print(sos_embds.shape)\n",
    "print('----')\n",
    "\n",
    "enc_outs = outputs.transpose(1, 2)\n",
    "print(enc_outs.shape)\n",
    "attn_outs = attn_outs.unsqueeze(2)\n",
    "print(attn_outs.shape)\n",
    "context_vecs = torch.bmm(enc_outs, attn_outs) # weighted sum of the encoder hidden states (weighted by the attention weights) gives the context vectors\n",
    "print(context_vecs.shape) # the context vector is a summary of the sequence, highlighting some parts of the sequence based on the attention mechanism\n",
    "print('----')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 256])\n",
      "torch.Size([1, 10, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(sos_embds.shape)\n",
    "context_vecs = context_vecs.squeeze(2).unsqueeze(0)  # shape becomes (1, 10, 1024)\n",
    "print(context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_og.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1280])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50257])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_inp = torch.cat((sos_embds, context_vecs), dim=2) # shape becomes (1, 10, 1280)\n",
    "print(rnn_inp.shape)\n",
    "rnn = nn.GRU((ENC_HID_DIM * 2) + EMB_DIM, DEC_HID_DIM)\n",
    "rnn_outs = rnn(rnn_inp, hidden_og.unsqueeze(0))\n",
    "\n",
    "out = rnn_outs[0].squeeze(0)\n",
    "hid = rnn_outs[1].squeeze(0)\n",
    "embeds = sos_embds.squeeze(0)\n",
    "weighted = context_vecs.squeeze(0)\n",
    "\n",
    "fc_out = nn.Linear((ENC_HID_DIM * 2) + DEC_HID_DIM + EMB_DIM, INPUT_DIM)\n",
    "testing = fc_out(torch.cat((out, weighted, embeds), dim=1))\n",
    "testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg=None, teacher_forcing_ratio=0.5, max_len=512):\n",
    "        # src = [batch size, src len]\n",
    "        # trg = [batch size, trg len]\n",
    "        if trg is not None:\n",
    "            batch_size = trg.shape[0]\n",
    "            trg_len = trg.shape[1]\n",
    "        else:\n",
    "            batch_size = src.shape[0]\n",
    "            trg_len = max_len  # set a maximum length for the generated sequence\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[:, 0] if trg is not None else torch.tensor([tokenizer.bos_token_id]).to(self.device)\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force and trg is not None else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define your parameters\n",
    "INPUT_DIM = tokenizer.vocab_size\n",
    "OUTPUT_DIM = tokenizer.vocab_size\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "ENC_HID_DIM = 256\n",
    "DEC_HID_DIM = 256\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "# Initialize attention, encoder, and decoder\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM).to(device)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn).to(device)\n",
    "\n",
    "# Initialize Seq2Seq model\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "# # Move your test batch to the correct device\n",
    "# test_batch = train_inputs[:10]\n",
    "# test_batch = test_batch.to(device)\n",
    "\n",
    "# # You should also supply the target tensor, which you can initially set as the test batch itself\n",
    "# test_targets = train_targets[:10]\n",
    "\n",
    "# # Finally, call the model\n",
    "# output = model(test_batch, test_targets)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_fn = CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# prepare data\n",
    "train_dataset = TensorDataset(train_inputs[:100], train_targets[:100])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# train the model\n",
    "model.train()  # set the model to training mode\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # move inputs and targets to the correct device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        output = model(inputs, targets)\n",
    "\n",
    "        # compute the loss\n",
    "        output = output.view(-1, output.shape[-1])  # flatten the outputs\n",
    "        targets = targets.view(-1)  # flatten the targets\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # print loss for every 100 steps\n",
    "        # if i % 100 == 0:\n",
    "        print(f'Epoch: {epoch}, Step: {i}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './seq2seq1.pt'\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article: Sally Forrest, an actress-dancer who graced the silver screen throughout the '40s and '50s in MGM musicals and films such as the 1956 noir While the City Sleeps died on March 15 at her home in Beverly Hills, California. Forrest, whose birth name was Katherine Feeney, was 86 and had long battled cancer. Her publicist, Judith Goffin, announced the news Thursday. Scroll down for video . Actress: Sally Forrest was in the 1951 Ida Lupino-directed film 'Hard, Fast and Beautiful' (left) and the 1956 Fritz Lang movie 'While the City Sleeps' A San Diego native, Forrest became a protege of Hollywood trailblazer Ida Lupino, who cast her in starring roles in films including the critical and commercial success Not Wanted, Never Fear and Hard, Fast and Beautiful. Some of Forrest's other film credits included Bannerline, Son of Sinbad, and Excuse My Dust, according to her iMDB page. The page also indicates Forrest was in multiple Climax! and Rawhide television episodes. Forrest appeared as herself in an episode of The Ed Sullivan Show and three episodes of The Dinah Shore Chevy Show, her iMDB page says. She also starred in a Broadway production of The Seven Year Itch. City News Service reported that other stage credits included As You Like It, No, No, Nanette and Damn Yankees. Forrest married writer-producer Milo Frank in 1951. He died in 2004. She is survived by her niece, Sharon Durham, and nephews, Michael and Mark Feeney. Career: A San Diego native, Forrest became a protege of Hollywood trailblazer Ida Lupino, who cast her in starring roles in films .\n",
      "Summarized Article: ! Navy SEAL Women, Monroe,,,,,,, in the 1960s.\n",
      "The,,,,,, and 1960s.\n",
      "The,,,,, and 1960s.\n",
      "The film,,,, and 1960s.\n",
      "The film,,,, and 1960s.\n",
      "The film, include,,,,, and 1960s.\n",
      "The film,,,,, and 1960s.\n",
      "The film, include,,,,, and 1960s, and 1960s.\n",
      "The film,,,,, and 1960s, and 1960s.\n",
      "The film, include,,,,, and 1960s, and 1960s.\n",
      "The film,,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film, include,,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film, include,,,,, and 1960s, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film,,,, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s, and 1960s.\n",
      "The movie, and 1960s, and 1960s.\n",
      "The film, the,,, and 1960s,\n",
      "Original Article: A middle-school teacher in China has inked hundreds of sketches that are beyond be-leaf. Politics teacher Wang Lian, 35,  has created 1000 stunning ink drawings covering subjects as varied as cartoon characters and landscapes to animals, birds according to the People's Daily Online. The intricate scribbles on leaves feature Wang's favourite sites across the city of Nanjing, which include the Presidential Palace, Yangtze River Bridge, the ancient Jiming Temple and the Qinhuai River. Natural canvas: Artist and teacher Wang Lian has done hundreds of drawings, like this temple, on leaves she collects in the park and on the streets . Delicate: She uses an ink pen to gently draw the local scenes and buildings on the dried out leaves . 'Although teaching politics is my job, drawing is my passion and hobby,' said Wang. 'I first tried drawing on leaves about 10 years ago and fell in love with it as an art form immediately. 'It's like drawing on very old parchment paper, you have to be really careful that you don't damage the leaf because it is very fragile and this helps focus your attention and abilities.' Wang started giving the drawings away on Christmas Eve in 2012 when her junior high school son came home saying he wanted to prepare some gifts for his classmates. Being an avid painter, Wang decided to give her son's friends unique presents of gingko leaf paintings. Wang loves gingko leaves and will often pick them up along Gingko Avenue, near to her school, in Nanjing in east China's Jiangsu province. Every autumn she collects about 2,000 leaves from the ground to ensure she has enough to cover spoils too. Intricate: Teacher Wang has drawn hundreds of local scenes on leaves she has collected from the park . Hobby: The artist collects leaves every autumn and dries them out so she can sketch these impressive building scenes . 'The colour and shape of gingko leaves are particularly beautiful,' she said. 'I need to collect around 2000 leaves because this will include losses'. She takes them home where she then presses them between the pages of books. 'Luckily, I have quite a lot of books and I try to use old ones or ones that I've already read so I don't end up with nothing to read.' Once they are dried, she carefully takes each one and using an ink fountain pen creates her masterpieces. She said: 'Some people are into capturing beauty through photography, but for me, a digitalised image just isn't the same. New leaf: Politics teacher Wang Lian has drawn hundreds of doodles on leaves for the last 10 years . 'By drawing what I see I become far more a part of the process and part of the final piece. 'One day I hope to be able to put my collection on display, but for now it's really just for my own pleasure.' Wang's leaf paintings are turned into bookmarks, postcards and sometimes even given as gifts to her her students so she can share the beauty of leaf paintings. But locals who have had the luck of being able to see Wang's art have been gobsmacked. Local art collector On Hao, 58, said: 'These are truly remarkable and beautiful creations. 'She has so much talent she is wasted in teaching.'\n",
      "Summarized Article: ! Today,,,,, has been been to of the of the of the.\n",
      ".\n",
      ".\n",
      "She has been been to of the and of the of the.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "She has been to of the and of the and of the..\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      " to the the.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ",000,000 and the..\n",
      "..\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ",000,000 and the..\n",
      "..\n",
      ".\n",
      ".\n",
      ".\n",
      ",000, and the..\n",
      "..\n",
      "..\n",
      ".\n",
      ",000, and the..\n",
      "..\n",
      "..\n",
      "..\n",
      ",000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "..\n",
      "..\n",
      ".,000, and the...\n",
      "...\n",
      "..\n",
      ",000 and the...\n",
      "..\n",
      "..\n",
      ",000 and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      "..\n",
      ",000 and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      "..\n",
      ",000 and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,000, and the...\n",
      "...\n",
      ".,\n",
      "Original Article: A man convicted of killing the father and sister of his former girlfriend in a fiery attack on the family's Southern California home was sentenced to death on Tuesday. Iftekhar Murtaza, 30, was sentenced for the murders of Jay Dhanak, 56, and his daughter Karishma, 20, in May 2007, the Orange County district attorney's office said. Murtaza was convicted in December 2013 of killing the pair in an attempt to reunite with his then-18-year-old ex-girlfriend Shayona Dhanak. She had ended their relationship citing her Hindu family's opposition to her dating a Muslim. To be executed: Iftekhar Murtaza, 30, was sentenced to death Tuesday for the May 21, 2007 murders of his ex-girlfriend's father and sister and the attempted murder of her mother . Authorities said Murtaza and a friend torched the family's Anaheim Hills home and kidnapped and killed Dhanak's father and sister, leaving their stabbed bodies burning in a park 2 miles from Dhanak's dorm room at the University of California, Irvine. Dhanak's mother, Leela, survived the attack. She was stabbed and left unconscious on a neighbor's lawn. Murtaza was interviewed by police several days later and arrested at a Phoenix airport with a ticket to his native Bangladesh and more than $11,000 in cash. Jurors recommended that Murtaza be sentenced to death for the crimes. Attack: Murtaza torched his ex-girlfriend's family's Orange County home after they broke-up, believing the murders of her family would reunited them . Religious differences: Murtaza dated Shayona Dhanak when she was 18 in 2007. She broke up with him when her Hindu parents allegedly told her they would stop paying her college tuition if she continued to date the Muslim man . Two of his friends were also sentenced to life in prison for the murders, but one of them, Vitaliy Krasnoperov, recently had his conviction overturned on appeal. Authorities said Krasnoperov hatched the plot to kill the Dhanaks with Murtaza and tried to help him hire a hit man. They said another friend, Charles Murphy Jr., helped Murtaza carry out the killings after Dhanak said she planned to go on a date with someone else. During the trial, Murtaza testified that he told many people he wanted to kill the Dhanaks because he was distraught over the breakup, but he said he didn't mean it literally. Didn't do it alone: Two of Murtaza's friends have been convicted in connection to the killings . Killer: Leela Dhanak testified how Iftekhar Murtaza, seen in this August photo, murdered her husband and elder daughter in a failed attempt to win over her younger daughter . Bloodbath: Autopsy reports showed Jayprakash Dhanak (left) suffered 29 stab wounds to his body, while a pathologist testified that Karishma Dhanak (right) was alive when her throat was slit and her body set alight .\n",
      "Summarized Article: ! Hill,,,,,, was killed in the family's family.\n",
      "He was killed in the family's family in the family.\n",
      ".\n",
      "He was killed his family and family to the family in the.\n",
      ".\n",
      ".\n",
      "\n",
      ",,,,, and his family and was killed in the..\n",
      "His family was family, was killed in the family and his family.\n",
      ".\n",
      ".\n",
      ",,, and his family.\n",
      ".\n",
      " family members of the family's family.\n",
      ".\n",
      ".\n",
      ",,, and his family.\n",
      ".\n",
      ".\n",
      ", and family members.\n",
      ".\n",
      ".\n",
      ", and family members.\n",
      ".\n",
      ".\n",
      ", and family members.\n",
      ".\n",
      ".\n",
      ", and family members.\n",
      ".\n",
      ".\n",
      ", and family members.\n",
      ".\n",
      ".\n",
      ", and his family.\n",
      ". family.\n",
      " to the family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of the family's family.\n",
      ". family members of\n",
      "Original Article: Avid rugby fan Prince Harry could barely watch as England came up just short of the 26-point margin needed to win their first Six Nations since 2011 in a pulsating match at Twickenham. In a breathtaking spectacle, England defeated France 55-35 in 'Le Crunch' - just six points short of the total required to lift the trophy. Sporting a navy blue suit, the fourth-in-line to the throne squirmed in his seat as England got off to a difficult start, despite an early try. Scroll down for video . Stress: The Prince can barely watch as England beat France 55-35 but narrowly missed out on the Six Nations . Taking its toll: Harry looks anxious as England struggled to cope with France's impressive start to the match . Passion: Prince Harry belts out the national anthem, seated behind England coach Stuart Lancaster . Despite their herculean effort, England could not find a final try and finished second in the championship, behind Ireland. After the match, England head coach Stuart Lancaster praised his side for 'one of the most courageous performances' he has seen from his side. 'It will go down as one of the great games of rugby,' he added. Earlier in the day, Ireland thrashed 40-10 in Edinburgh to mark a dismal campaign for the Scots and an impressive Wales ran riot in Rome, thumping Italy 61-20. All smiles: The fourth-in-line to the throne grins alongside students from Reigate School, in Surrey . Before England's crunch match against France, Prince Harry had met girls from Reigate School and The Quest Academy, Croydon, who had played in the warm-up game. Harry - who is a Vice Patron of the Rugby Football Union (RFU) - also chatted with members of the armed forces at Twickenham . Looking dapper in his navy suit, the fourth-in-line to the throne then took his seat in the stand before singing the national anthem with gusto. Patriotic: Harry chats to a member of the army - he announced this week he will quit the army in the summer . Pointing the way: The Prince is an avid rugby fan - England and Wales host the World Cup later this year . Suave: Harry, in a sharp navy suit, walks along the side of the hallowed Twickenham turf before the match . The Six Nations is the last competitive rugby tournament before England host the World Cup later this year. The tournament begins on September 18 with England taking on Fiji at Twickenham. In 2014 Prince Harry was named as patron of the RFU's All Schools campaign, which aims to bring rugby to 750 more schools by the Rugby World Cup in 2019. Looking up: Prince Harry takes his seat in the stands with Bernard Lapasset, left, chairman of the IRB . Role model: Harry chats to students from Reigate School, who had played before England's match vs France . Charismatic: The Prince - patron of the RFU's All Schools campaign, jokes with the girls before a photo shoot . He is also Patron of the RFU Injured Players Foundation. Although one of the most prominent royal rugby fans (he was famously in attendance when England lifted the Webb Ellis Cup in Australia in 2003), the Prince is by no means the only one. His brother Prince William is also a fan and enjoys a similar position at the Welsh RFU while the Princess Royal is patron of Scottish rugby and regularly appears at Murrayfield on match day.\n",
      "Summarized Article: ! rugby Lions beat a in England in the tournament in the.\n",
      "England.\n",
      "England- in the in England.\n",
      "England.\n",
      "England.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England-.\n",
      "England in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England-time to the the tournament.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England.\n",
      "England.\n",
      "England Slovenia in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England.\n",
      "England.\n",
      "England and Wales.\n",
      "England.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England..\n",
      "England.\n",
      "England and Wales.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England..\n",
      "England.\n",
      "England and Wales.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England..\n",
      "England.\n",
      "England and Wales.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the World Cup opener.\n",
      "England..\n",
      "England.\n",
      "England and Wales.\n",
      "England in the..\n",
      "England.\n",
      "England.\n",
      "England in the\n",
      "Original Article: A Triple M Radio producer has been inundated with messages from prospective partners after a workplace ploy. After Tuesday's Grill Team show, hosts Matty Johns, Mark Geyer and Gus Worland uploaded a picture of 26-year-old Nick Slater to Facebook with a mobile number where people could reach him. In less than 24 hours, he had received over 130 messages from a varied range of male and female listeners, reports News.com. Triple M producer Nick Slater, (C), pictured with his Grill Team hosts, was flooded with 130 voicemails in 24 hours . Workmates and Grill Team hosts Matty Johns, Mark Geyer and Gus Worland uploaded a picture of 26-year-old Nick Slater to Facebook with a mobile number where people could reach out . The ploy came about after a waitress handed the audio engineer her number while out at some work drinks. Unconvinced it was a one off, his colleagues decided to put it to the test and see if anyone else was romantically interested in him. 'The Producers had a few drinks on Friday & Handsome Nick got a number off the waitress in the first 10 minutes!' 'We don't believe him that this never happens to him. Here's Nicks number...let's see how many calls he gets!' Slater received a torrent of voicemails, ranging from date proposals to 'heavy panting' 26-year-old Slater, a sound engineer, and his Triple M Grill Team workmates . In the following 24 hours Slater received a torrent of voicemails, ranging from date proposals to 'heavy panting.' 'There was a wide range of messages from some nice girls and a few nice blokes as well. There was even a grandma in there too.,' he said. 'We went through and listened to most of them. It was mostly people looking for lust, telling me to give them a call … it was all good fun.' Slater said his long-term girlfriend Kimberley understood of the station's antics, and she found the gag 'hilarious.' Slater said his long-term girlfriend Kimberley (pictured)  found the umber ploy 'hilarious .\n",
      "Summarized Article: !-,,,,, a a, of a.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", a, with a,, a.\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", a, with a, and a.\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", a,, and a with a.\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ",000 a and a with a.\n",
      ".\n",
      ".\n",
      "The,000 a and a, and a.\n",
      ".\n",
      ".\n",
      ".\n",
      "The,000 a and a, and a.\n",
      ".\n",
      ".\n",
      ".\n",
      "The,000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ".\n",
      ",000 a staggering of the and a...\n",
      "..\n",
      ".\n",
      ".\n",
      ", a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a..\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      ".\n",
      ".\n",
      ", a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      ".\n",
      ".\n",
      ", a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      ".\n",
      ".\n",
      ", a staggering with a and.\n",
      ".\n",
      ".\n",
      ".\n",
      ",000 a staggering and a.\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select first 5 rows\n",
    "val_df_sample = val_df.head(5)\n",
    "articles = list(val_df_sample['article'])\n",
    "\n",
    "# Tokenize, pad and move to device\n",
    "inputs = [torch.tensor(tokenizer.encode(article, truncation=True, max_length=512)).unsqueeze(0) for article in articles]\n",
    "inputs = [input.to(device) for input in inputs]\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Loop through each article\n",
    "for i, input in enumerate(inputs):\n",
    "    with torch.no_grad():\n",
    "        # Get model output\n",
    "        output = model(input)\n",
    "        \n",
    "        # Get the predicted tokens\n",
    "        predicted_tokens = output.argmax(-1)\n",
    "        \n",
    "        # Convert the tokens back to words\n",
    "        predicted_article = tokenizer.decode(predicted_tokens[0])\n",
    "        \n",
    "        print(f'Original Article: {articles[i]}')\n",
    "        print(f'Summarized Article: {predicted_article}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq_attention",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
